{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M.0 Data initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4b0dda8f9eed:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>discret_pierre_detection</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff798571150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMBER_OF_THREADS_TO_USE = \"*\"\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[' + NUMBER_OF_THREADS_TO_USE + ']') \\\n",
    "    .appName('discret_pierre_detection') \\\n",
    "    .config('spark.driver.memory', '200g') \\\n",
    "    .config('spark.driver.maxResultSize', '15g') \\\n",
    "    .config('spark.rapids.sql.enabled','true') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "LocationPrefix = \"Paris\"\n",
    "DatasetPrefix = \"Cancan\"\n",
    "\n",
    "\n",
    "# those are the metadata used to sum the number of requests\n",
    "#meta = ['LocationId', 'MinuteWithinWeek']\n",
    "meta = ['WeeksGroup', 'LocationId', 'MinuteWithinWeek']\n",
    "\n",
    "# those are the metrics once we have gathered antennas and stuff\n",
    "#metrics = ['Call','SMS','Data','Mobility','Signalling','Emergency','Overload']\n",
    "metrics = ['Voice','SMS_3G','PS','CS','Call','SMS_4G','Service_Req','HO']\n",
    "\n",
    "\n",
    "SourceParquetFilesLoc = '/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris/'\n",
    "\n",
    "ParquetFilesSignaturesLoc = '/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_sigs_2/'\n",
    "ParquetFilesDistribsLoc = '/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_distribs_2/'\n",
    "\n",
    "ParquetFilesALRsLoc = '/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_ALR_2/'\n",
    "CsvFilesThresholdsLoc = '/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_Thresholds_2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_utc: string (nullable = true)\n",
      " |-- time_local: timestamp (nullable = true)\n",
      " |-- Voice: long (nullable = true)\n",
      " |-- PS: long (nullable = true)\n",
      " |-- SMS_3G: long (nullable = true)\n",
      " |-- CS: long (nullable = true)\n",
      " |-- Service_Req: long (nullable = true)\n",
      " |-- Call: long (nullable = true)\n",
      " |-- SMS_4G: long (nullable = true)\n",
      " |-- HO: long (nullable = true)\n",
      " |-- MinuteWithinWeek: integer (nullable = true)\n",
      " |-- WeeksGroup: integer (nullable = true)\n",
      " |-- WeekOfYear: integer (nullable = true)\n",
      " |-- LocationId: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- MinuteWithinWeek: long (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      " |-- WeeksGroup: integer (nullable = true)\n",
      " |-- LocationId: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- GammaParam: string (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      " |-- WeeksGroup: integer (nullable = true)\n",
      " |-- LocationId: integer (nullable = true)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3078 entries, 0 to 3077\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   WeeksGroup  3078 non-null   int64  \n",
      " 1   LocationId  3078 non-null   int64  \n",
      " 2   level1byPL  3078 non-null   float64\n",
      " 3   level2byPL  3078 non-null   float64\n",
      " 4   level3byPL  3078 non-null   float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 120.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#DistribsDFSP = spark.read.parquet('/WORKSPACE/Pierre/exports/Cancan_distribs_tmp/Paris/')\n",
    "\n",
    "\n",
    "OriginalDataDFSP = spark.read.parquet(SourceParquetFilesLoc)\n",
    "OriginalDataDFSP.printSchema()\n",
    "\n",
    "SignaturesDFSP = spark.read.parquet(ParquetFilesSignaturesLoc)\n",
    "SignaturesDFSP.printSchema()\n",
    "\n",
    "DistribsDFSP = spark.read.parquet(ParquetFilesDistribsLoc)\n",
    "DistribsDFSP.printSchema()\n",
    "\n",
    "ThresholdsDF = pd.read_csv(CsvFilesThresholdsLoc)\n",
    "print(ThresholdsDF.info(verbose=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1026 location groups\n",
      "All Weeks Ids:\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "All Groups Ids:\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "LocIdsList = sorted([x.LocationId for x in DistribsDFSP.select('LocationId').distinct().collect()])\n",
    "\n",
    "print(\"found \" + str(len(LocIdsList)) + \" location groups\")\n",
    "\n",
    "#print(LocIdsList)\n",
    "\n",
    "AllWeeksIdsList = sorted([x.WeekOfYear for x in OriginalDataDFSP.select('WeekOfYear').distinct().collect()])\n",
    "\n",
    "print(\"All Weeks Ids:\")\n",
    "print(AllWeeksIdsList)\n",
    "\n",
    "\n",
    "AllWeeksGroupsList = sorted([x.WeeksGroup for x in OriginalDataDFSP.select('WeeksGroup').distinct().collect()])\n",
    "\n",
    "print(\"All Groups Ids:\")\n",
    "print(AllWeeksGroupsList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALR computing:   1%|‚ñè         | 39/3078 [01:11<1:32:49,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3669120 entries, 0 to 10079\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   MinuteWithinWeek  int64  \n",
      " 1   WeeksGroup        int64  \n",
      " 2   WeekOfYear        int64  \n",
      " 3   LocationId        int64  \n",
      " 4   ALR               float64\n",
      " 5   Anomaly_Level     int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 196.0 MB\n"
     ]
    }
   ],
   "source": [
    "#from anr_discret import onlineMLbyPL\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "MinALSThreshold = 1 / (60*24*365.25*10)\n",
    "\n",
    "def compute_alr_eric_local(df:pd.DataFrame, distrib:dict, metrics:list) -> pd.DataFrame:\n",
    "    \"\"\"Computes the Anomaly Likelihood Rate (ALR) over the input dataframe.\n",
    "    The ALR corresponds to the sum of the logs of the p-value for each service data.\n",
    "    The p-value is obtained for each service data by fitting a Gamma distribution over the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The input dataframe (usually containing AE values)\n",
    "    distrib: dict\n",
    "        The error distribution parameters for all services\n",
    "    metrics: list\n",
    "        The list of column names corresponding to the service data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The same dataframe with the additional ALR column\n",
    "    \"\"\"\n",
    "\n",
    "    res = pd.DataFrame().reindex_like(df)\n",
    "    als = pd.DataFrame(index = res.index, columns = metrics)\n",
    "    \n",
    "    CopyCols = list(set(df.columns) - set(metrics))\n",
    "    res[CopyCols] = df[CopyCols].copy(deep=True)\n",
    "\n",
    "    for m in metrics:\n",
    "        mLoc = df.columns.get_loc(m)\n",
    "            \n",
    "        SeparationThresh = distrib.loc['thresh',m]\n",
    "        proba = distrib.loc['proba',m]\n",
    "        nvalues = distrib.loc['nvalues',m]\n",
    "        arg = distrib.loc['k',m]\n",
    "        loc = distrib.loc['loc',m]\n",
    "        scale = distrib.loc['theta',m]\n",
    "\n",
    "        if nvalues<3:\n",
    "            #print(\"case where the gamma law was not fitted on metric \" + m)\n",
    "            res.loc[:,m] = pd.Series(np.nan, index=df.index)\n",
    "        else:\n",
    "            # default value is 1-proba\n",
    "            res.loc[:,m] = pd.Series((1. - proba), index=df.index)\n",
    "            # the gamma law was fitted on this metric\n",
    "            indexThresh = df.index[df[m]>SeparationThresh]\n",
    "\n",
    "            res.loc[indexThresh,m] = (1. - proba) * stats.gamma.sf(df.loc[indexThresh, m], arg, loc=loc, scale=scale)\n",
    "            res.loc[indexThresh,m].clip(lower=MinALSThreshold, inplace=True)\n",
    "\n",
    "        als[m] = pd.Series(np.log(res[m]), index=res.index)\n",
    "\n",
    "    res['ALR'] = als.sum(axis=1)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def set_levels_local(df, thresh):\n",
    "    \"\"\"Set anomaly levels on the input data according to the ALR value at each timestamp.\n",
    "    The data can be labelled as: normal, pre-alert (level 1), alert (level 2), maximal anomaly (level 3).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The input dataframe with ALR values\n",
    "    thresh: pandas.core.frame.Series\n",
    "        The ALR thresholds of the dataframe for each anomaly level\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.core.frame.DataFrame\n",
    "        The dataframe with anomaly levels (0 to 3)\n",
    "    \"\"\"\n",
    "\n",
    "    df['Anomaly_Level'] = 0\n",
    "    df.loc[df.ALR < thresh['level1byPL'], 'Anomaly_Level'] = 1\n",
    "    df.loc[df.ALR < thresh['level2byPL'], 'Anomaly_Level'] = 2\n",
    "    df.loc[df.ALR < thresh['level3byPL'], 'Anomaly_Level'] = 3\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "totalALR = []\n",
    "\n",
    "\n",
    "with tqdm(total=len(LocIdsList)*len(AllWeeksGroupsList), desc='ALR computing') as pbar:\n",
    "    # run 2 imbricated loops, this hasn't much consequence on the output thanks to the filter / partitioning thing \n",
    "    for WGrp in AllWeeksGroupsList:\n",
    "    #for WGrp in range(0,1):\n",
    "        \n",
    "        GroupDFSP = OriginalDataDFSP.filter(OriginalDataDFSP.WeeksGroup==WGrp)\n",
    "        TrainWeeksIdsList = sorted([x.WeekOfYear for x in GroupDFSP.select('WeekOfYear').distinct().collect()])\n",
    "        TestWeeksIdsList = list(set(AllWeeksIdsList) - set(TrainWeeksIdsList))\n",
    "        \n",
    "        for LocId in LocIdsList:\n",
    "            \n",
    "            if LocId>20:\n",
    "                break\n",
    "\n",
    "            ReferenceDF = SignaturesDFSP.filter(SignaturesDFSP.LocationId == LocId).toPandas()\n",
    "\n",
    "            ErrorsDFsList = []\n",
    "            for wk in TestWeeksIdsList:\n",
    "                wkDF = OriginalDataDFSP.drop('time_local').drop('time_utc').filter((OriginalDataDFSP.WeekOfYear==wk) & (OriginalDataDFSP.LocationId == LocId)).toPandas().set_index('MinuteWithinWeek')\n",
    "                wkDF = wkDF.reindex(range(0,24*7*60), fill_value=0).assign(WeekOfYear=wk, LocationId=LocId, WeeksGroup=WGrp).fillna(0).reset_index()\n",
    "\n",
    "                for m in metrics:\n",
    "                    #wkDF[m] = abs(wkDF[m] - ReferenceDF[m])\n",
    "                    wkDF[m] = wkDF[m] - ReferenceDF[m]\n",
    "\n",
    "                #print(\"length wkDF :\" + str(len(wkDF.index)))\n",
    "                ErrorsDFsList.append( wkDF )\n",
    "\n",
    "            AbsErrors = pd.concat(ErrorsDFsList)\n",
    "            #print(AbsErrors.info(verbose=True))\n",
    "            #print(AbsErrors.describe())\n",
    "            \n",
    "\n",
    "            GammaLawDF = DistribsDFSP.filter((DistribsDFSP.LocationId==LocId) & (DistribsDFSP.WeeksGroup==WGrp)).toPandas()\n",
    "            GammaLawDF.set_index('GammaParam', inplace=True)\n",
    "            #print(GammaLawDF.info(verbose=True))\n",
    "            #print(GammaLawDF.describe())\n",
    "            #print(GammaLawDF)\n",
    "\n",
    "\n",
    "            AnomalyLevel = compute_alr_eric_local(AbsErrors, GammaLawDF, metrics)\n",
    "            #print(\"==== alert levels DF ====\")\n",
    "            #print(AnomalyLevel.info(verbose=True))\n",
    "            #print(AnomalyLevel.describe())\n",
    "            #print(AnomalyLevel)\n",
    "\n",
    "            thresholds = ThresholdsDF.loc[(ThresholdsDF['LocationId']==LocId) & (ThresholdsDF['WeeksGroup']==WGrp)]\n",
    "            #print(\"==== thresholds DF ====\")\n",
    "            #print(thresholds.info(verbose=True))\n",
    "            #print(thresholds.describe())\n",
    "            #print(thresholds)\n",
    "\n",
    "            ThreshDict = thresholds.to_dict(orient='records')[0]\n",
    "            #print(ThreshDict)\n",
    "            #break\n",
    "\n",
    "            # this one should not be used anymore actually\n",
    "            #replace_inf_local(AnomalyLevel, metrics, ThreshDict)\n",
    "\n",
    "\n",
    "            set_levels_local(AnomalyLevel, ThreshDict)\n",
    "            #AnomalyLevel = AnomalyLevel.fillna(0)\n",
    "            #print(\"==== anomaly levels DF ====\")\n",
    "            #print(AnomalyLevel.info(verbose=True))\n",
    "            #print(AnomalyLevel.describe())\n",
    "            #print(AnomalyLevel)\n",
    "\n",
    "\n",
    "            totalALR.append(AnomalyLevel.drop(columns=metrics))\n",
    "\n",
    "            pbar.update(1)\n",
    "        #break\n",
    "    #break\n",
    "\n",
    "totalALRDF = pd.concat(totalALR)\n",
    "\n",
    "totalALRDF.info(verbose=True)\n",
    "#print(totalALRDF.describe())\n",
    "#print(totalALRDF)\n",
    "\n",
    "\n",
    "#totalALRDF.drop(columns=metrics).to_parquet(path='tests/Cancan_Paris_alerts_eric_parquetAbs', partition_cols=['week_of_year','LocationId'], index=False)\n",
    "\n",
    "#totalALRDF.to_parquet(path=ParquetFilesALRsLoc, partition_cols=['WeeksGroup','LocationId'], index=False)\n",
    "\n",
    "#this is the bit of code we wish to adapt to the new format\n",
    "\n",
    "    # compute anomaly likelihood rates\n",
    "#    with tqdm(total=len(errors.keys()), desc='ALR computing') as pbar:\n",
    "#        for k,df in errors.items():\n",
    "#            errors[k] = offlineML.compute_alr(df, distributions[k], metrics)\n",
    "#            pbar.update(1)\n",
    "    \n",
    "    # Set ALR thresholds\n",
    "#    errors_df = pd.concat([df for df in errors.values()])\n",
    "\n",
    "    # apply the offlineML functions to aggregate thresholds for each antenna\n",
    "#    thresholds = errors_df.groupby(coords).ALR.agg([offlineML.level1, offlineML.level2, offlineML.level3])\n",
    "\n",
    "    # don't forget to store the index or the following will be annoying\n",
    "#    thresholds.reset_index(inplace=True)\n",
    "#    thresholds.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/test_multilevel_thresholds_sample_test_w' + str(testWeek) + '.csv', index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "('Did not pass numpy.dtype object', 'Conversion failed for column index with type int64')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29370a4e80e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotalALRDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_test/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WeekOfYear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LocationId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m             \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m         )\n\u001b[1;32m   2374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, path, compression, index, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mfrom_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"preserve_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfrom_pandas_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_fsspec_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"filesystem\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_to_convert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_can_definitely_zero_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    563\u001b[0m             e.args += (\"Conversion failed for column {!s} with type {!s}\"\n\u001b[1;32m    564\u001b[0m                        .format(col.name, col.dtype),)\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfield_nullable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             raise ValueError(\"Field {} was non-nullable but pandas column \"\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/pandas_compat.py\u001b[0m in \u001b[0;36mconvert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         except (pa.ArrowInvalid,\n\u001b[1;32m    561\u001b[0m                 \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrowNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/array.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/rapids/lib/python3.7/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column index with type int64')"
     ]
    }
   ],
   "source": [
    "totalALRDF.to_parquet(path='/WORKSPACE/Pierre/Cancan2022/Cancan2022_Paris_test/', partition_cols=['WeekOfYear','LocationId'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2489760 entries, 0 to 10079\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   MinuteWithinWeek  int64  \n",
      " 1   time_utc          object \n",
      " 2   Voice             float64\n",
      " 3   PS                float64\n",
      " 4   SMS_3G            float64\n",
      " 5   CS                float64\n",
      " 6   Service_Req       float64\n",
      " 7   Call              float64\n",
      " 8   SMS_4G            float64\n",
      " 9   HO                float64\n",
      " 10  WeeksGroup        int64  \n",
      " 11  WeekOfYear        int64  \n",
      " 12  LocationId        int64  \n",
      " 13  ALR               float64\n",
      " 14  Anomaly_Level     int64  \n",
      "dtypes: float64(9), int64(5), object(1)\n",
      "memory usage: 303.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinuteWithinWeek</th>\n",
       "      <th>Voice</th>\n",
       "      <th>PS</th>\n",
       "      <th>SMS_3G</th>\n",
       "      <th>CS</th>\n",
       "      <th>Service_Req</th>\n",
       "      <th>Call</th>\n",
       "      <th>SMS_4G</th>\n",
       "      <th>HO</th>\n",
       "      <th>WeeksGroup</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>LocationId</th>\n",
       "      <th>ALR</th>\n",
       "      <th>Anomaly_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.489760e+06</td>\n",
       "      <td>3.830400e+05</td>\n",
       "      <td>3.830400e+05</td>\n",
       "      <td>3.830400e+05</td>\n",
       "      <td>3.830400e+05</td>\n",
       "      <td>1.340640e+06</td>\n",
       "      <td>1.340640e+06</td>\n",
       "      <td>1.340640e+06</td>\n",
       "      <td>1.340640e+06</td>\n",
       "      <td>2.489760e+06</td>\n",
       "      <td>2.489760e+06</td>\n",
       "      <td>2.489760e+06</td>\n",
       "      <td>2.489760e+06</td>\n",
       "      <td>2.489760e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.039500e+03</td>\n",
       "      <td>9.495764e-01</td>\n",
       "      <td>9.368887e-01</td>\n",
       "      <td>9.563542e-01</td>\n",
       "      <td>9.548716e-01</td>\n",
       "      <td>9.736030e-01</td>\n",
       "      <td>9.541252e-01</td>\n",
       "      <td>9.566674e-01</td>\n",
       "      <td>9.762672e-01</td>\n",
       "      <td>1.473684e+00</td>\n",
       "      <td>1.763158e+01</td>\n",
       "      <td>1.169231e+01</td>\n",
       "      <td>-1.675106e-01</td>\n",
       "      <td>3.094274e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.909846e+03</td>\n",
       "      <td>1.000783e-01</td>\n",
       "      <td>1.408191e-01</td>\n",
       "      <td>9.533102e-02</td>\n",
       "      <td>1.039937e-01</td>\n",
       "      <td>7.016292e-02</td>\n",
       "      <td>9.757969e-02</td>\n",
       "      <td>1.115775e-01</td>\n",
       "      <td>7.974912e-02</td>\n",
       "      <td>4.993071e-01</td>\n",
       "      <td>4.093777e+00</td>\n",
       "      <td>4.777909e+00</td>\n",
       "      <td>7.048598e-01</td>\n",
       "      <td>6.469319e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.312733e-08</td>\n",
       "      <td>6.453268e-11</td>\n",
       "      <td>8.499578e-10</td>\n",
       "      <td>7.117869e-10</td>\n",
       "      <td>3.006927e-08</td>\n",
       "      <td>2.102209e-05</td>\n",
       "      <td>6.832305e-39</td>\n",
       "      <td>1.688429e-65</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>-1.491862e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.519750e+03</td>\n",
       "      <td>9.534392e-01</td>\n",
       "      <td>9.580853e-01</td>\n",
       "      <td>9.588073e-01</td>\n",
       "      <td>9.690256e-01</td>\n",
       "      <td>9.752646e-01</td>\n",
       "      <td>9.589396e-01</td>\n",
       "      <td>9.682639e-01</td>\n",
       "      <td>9.798909e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-1.172378e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.039500e+03</td>\n",
       "      <td>9.539683e-01</td>\n",
       "      <td>9.597332e-01</td>\n",
       "      <td>9.740873e-01</td>\n",
       "      <td>9.693552e-01</td>\n",
       "      <td>9.823115e-01</td>\n",
       "      <td>9.680357e-01</td>\n",
       "      <td>9.738095e-01</td>\n",
       "      <td>9.837798e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>-8.245451e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.559250e+03</td>\n",
       "      <td>9.769544e-01</td>\n",
       "      <td>9.674107e-01</td>\n",
       "      <td>9.753373e-01</td>\n",
       "      <td>9.742063e-01</td>\n",
       "      <td>9.972024e-01</td>\n",
       "      <td>9.755842e-01</td>\n",
       "      <td>9.753671e-01</td>\n",
       "      <td>9.893651e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.007900e+04</td>\n",
       "      <td>9.779431e-01</td>\n",
       "      <td>9.674107e-01</td>\n",
       "      <td>9.753373e-01</td>\n",
       "      <td>9.757826e-01</td>\n",
       "      <td>9.998512e-01</td>\n",
       "      <td>9.948810e-01</td>\n",
       "      <td>9.963988e-01</td>\n",
       "      <td>9.964087e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MinuteWithinWeek         Voice            PS        SMS_3G  \\\n",
       "count      2.489760e+06  3.830400e+05  3.830400e+05  3.830400e+05   \n",
       "mean       5.039500e+03  9.495764e-01  9.368887e-01  9.563542e-01   \n",
       "std        2.909846e+03  1.000783e-01  1.408191e-01  9.533102e-02   \n",
       "min        0.000000e+00  1.312733e-08  6.453268e-11  8.499578e-10   \n",
       "25%        2.519750e+03  9.534392e-01  9.580853e-01  9.588073e-01   \n",
       "50%        5.039500e+03  9.539683e-01  9.597332e-01  9.740873e-01   \n",
       "75%        7.559250e+03  9.769544e-01  9.674107e-01  9.753373e-01   \n",
       "max        1.007900e+04  9.779431e-01  9.674107e-01  9.753373e-01   \n",
       "\n",
       "                 CS   Service_Req          Call        SMS_4G            HO  \\\n",
       "count  3.830400e+05  1.340640e+06  1.340640e+06  1.340640e+06  1.340640e+06   \n",
       "mean   9.548716e-01  9.736030e-01  9.541252e-01  9.566674e-01  9.762672e-01   \n",
       "std    1.039937e-01  7.016292e-02  9.757969e-02  1.115775e-01  7.974912e-02   \n",
       "min    7.117869e-10  3.006927e-08  2.102209e-05  6.832305e-39  1.688429e-65   \n",
       "25%    9.690256e-01  9.752646e-01  9.589396e-01  9.682639e-01  9.798909e-01   \n",
       "50%    9.693552e-01  9.823115e-01  9.680357e-01  9.738095e-01  9.837798e-01   \n",
       "75%    9.742063e-01  9.972024e-01  9.755842e-01  9.753671e-01  9.893651e-01   \n",
       "max    9.757826e-01  9.998512e-01  9.948810e-01  9.963988e-01  9.964087e-01   \n",
       "\n",
       "         WeeksGroup    WeekOfYear    LocationId           ALR  Anomaly_Level  \n",
       "count  2.489760e+06  2.489760e+06  2.489760e+06  2.489760e+06   2.489760e+06  \n",
       "mean   1.473684e+00  1.763158e+01  1.169231e+01 -1.675106e-01   3.094274e-03  \n",
       "std    4.993071e-01  4.093777e+00  4.777909e+00  7.048598e-01   6.469319e-02  \n",
       "min    1.000000e+00  1.100000e+01  4.000000e+00 -1.491862e+02   0.000000e+00  \n",
       "25%    1.000000e+00  1.400000e+01  8.000000e+00 -1.172378e-01   0.000000e+00  \n",
       "50%    1.000000e+00  1.800000e+01  1.200000e+01 -8.245451e-02   0.000000e+00  \n",
       "75%    2.000000e+00  2.100000e+01  1.600000e+01  0.000000e+00   0.000000e+00  \n",
       "max    2.000000e+00  2.400000e+01  1.900000e+01  0.000000e+00   3.000000e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalALRDF.info(verbose=True)\n",
    "totalALRDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalALRDF.ALR.plot.hist(bins=250, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ThresholdsDF.drop(columns=['LocationId','WeeksGroup']).plot.hist(bins=250, alpha=0.5, logy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 599\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  900 non-null    int64  \n",
      " 1   LocationId  900 non-null    int64  \n",
      " 2   WeeksGroup  900 non-null    int64  \n",
      " 3   level1byPL  900 non-null    float64\n",
      " 4   level2byPL  900 non-null    float64\n",
      " 5   level3byPL  900 non-null    float64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 49.2 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 900 entries, 0 to 599\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  900 non-null    int64  \n",
      " 1   LocationId  900 non-null    int64  \n",
      " 2   WeeksGroup  900 non-null    int64  \n",
      " 3   level1byPL  900 non-null    float64\n",
      " 4   level2byPL  900 non-null    float64\n",
      " 5   level3byPL  900 non-null    float64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 49.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ThresholdsDF.info(verbose=True))\n",
    "print(ThresholdsDF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  300 non-null    int64  \n",
      " 1   LocationId  300 non-null    int64  \n",
      " 2   WeeksGroup  300 non-null    int64  \n",
      " 3   level1byPL  300 non-null    float64\n",
      " 4   level2byPL  300 non-null    float64\n",
      " 5   level3byPL  300 non-null    float64\n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 14.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(CsvFilesThresholdsLoc).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CsvFilesThresholdsLoc = 'exports/' + DatasetPrefix + '_thresholds_tmp_' + LocationPrefix + '.csv'\n",
    "#totalALRDF.to_csv('exports/Cancan_Paris_alerts_grp12.csv')\n",
    "\n",
    "totalALRDF.drop(columns=metrics).to_parquet(path='exports/Cancan_Paris_alerts_grp0_parquet', partition_cols=['week_of_year','LocationId'], index=False)\n",
    "\n",
    "# apply the offlineML functions to aggregate thresholds for each antenna\n",
    "#thresholds = totalALRDF.groupby(['LocationId', 'WeeksGroup']).ALR.agg([offlineMLbyPL.level1, offlineMLbyPL.level2, offlineMLbyPL.level3])\n",
    "\n",
    "# don't forget to store the index or the following will be annoying\n",
    "#thresholds.reset_index(inplace=True)\n",
    "#thresholds.to_csv(CsvFilesThresholdsLoc, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1736/3078 [4:05:59<3:41:53,  9.92s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "signatureDFs = []\n",
    "\n",
    "ColumnsDropList = []\n",
    "for m in metrics:\n",
    "    ColumnsDropList.append(m+'_ref')\n",
    "\n",
    "count = 0\n",
    "\n",
    "distributionsDFList = []\n",
    "    \n",
    "with tqdm(total=len(LocIdsList)*len(WeekIdsList), desc='Signature extraction') as pbar:\n",
    "    # run 2 imbricated loops, this hasn't much consequence on the output thanks to the filter / partitioning thing \n",
    "    for WeekGpId in WeekIdsList:\n",
    "        for LocId in LocIdsList:\n",
    "            #if LocId>10:\n",
    "            #    break\n",
    "            # gather all the data corresponding to the training group and the corresponding location\n",
    "            # start with the location\n",
    "            #OriginalDataLocSP = OriginalDataDFSP.filter(OriginalDataDFSP.LocationId == LocId)\n",
    "            \n",
    "            #start_time = time.time()\n",
    "            referenceDF = wholeDF.loc[(wholeDF['WeeksGroup']==WeekGpId) & (wholeDF['LocationId']==LocId)].drop(columns=['LocationId'])\n",
    "            #print(\"grabbing the ref time performed in \" + str((time.time() - start_time)) + \" seconds\")\n",
    "            \n",
    "            # then the corresponding weeks. I believe that it's more convenient by unioning stuff\n",
    "            #start_time = time.time()\n",
    "            \n",
    "            #OriginalDataDFList = []\n",
    "            ErrorsDFsList = []\n",
    "            for wk in TrainWeeksGroupsList[WeekGpId]:\n",
    "                wkDF = OriginalDataDFSP.drop('time_utc').drop('time_local').filter((OriginalDataDFSP.week_of_year==wk) & (OriginalDataDFSP.LocationId == LocId)).toPandas().set_index('MinuteWithinWeek')\n",
    "                wkDF = wkDF.reindex(range(0,24*7*60), fill_value=np.nan).assign(week_of_year=wk, LocationId=LocId)\n",
    "                \n",
    "                for m in metrics:\n",
    "                    wkDF[m] = abs(wkDF[m] - referenceDF[m])\n",
    "                \n",
    "                #print(\"length wkDF :\" + str(len(wkDF.index)))\n",
    "                \n",
    "                ErrorsDFsList.append( wkDF )\n",
    "            \n",
    "            errors = pd.concat(ErrorsDFsList)\n",
    "\n",
    "            #if count>=10:\n",
    "            #    print(errors.info())\n",
    "            #    print(errors.describe())\n",
    "            #    print(errors)\n",
    "            \n",
    "            #distributions = offlineMLbyPL.get_distrib_params(errors, meta=meta, metrics=metrics)\n",
    "            distribution = pd.DataFrame(np.nan, index=['k','loc','theta'], columns=['LocationId', 'WeeksGroup', *metrics])\n",
    "            distribution = distribution.assign(WeeksGroup=WeekGpId).assign(LocationId=LocId)\n",
    "            distrib = offlineMLbyPL.fit_distribution(errors, metrics)\n",
    "            for m in metrics:\n",
    "                params = distrib[m]\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "                distribution[m].iloc[0] = arg[0]\n",
    "                distribution[m].iloc[1] = loc\n",
    "                distribution[m].iloc[2] = scale\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            #if count>10:\n",
    "            #    print(distribution.info())\n",
    "            #    print(distribution.describe())\n",
    "            #    print(distribution)\n",
    "            #    break\n",
    "\n",
    "            pbar.update(1)\n",
    "            \n",
    "            distribution.index.names = ['GammaParam']\n",
    "            distribution = distribution.reset_index()\n",
    "            \n",
    "            distributionsDFList.append(distribution)\n",
    "\n",
    "            \n",
    "distributionsDF = pd.concat(distributionsDFList)\n",
    "#print(distributionsDF.info())\n",
    "#print(distributionsDF.describe())\n",
    "#print(distributionsDF)\n",
    "\n",
    "\n",
    "distributionsDF.to_parquet(path=ParquetFilesDistribsLoc, partition_cols=['WeeksGroup','LocationId'], index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9234 entries, k to theta\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   LocationId   9234 non-null   int64  \n",
      " 1   WeeksGroup   9234 non-null   int64  \n",
      " 2   Voice        9150 non-null   float64\n",
      " 3   SMS_3G       9126 non-null   float64\n",
      " 4   PS           9147 non-null   float64\n",
      " 5   CS           9150 non-null   float64\n",
      " 6   Call         6238 non-null   float64\n",
      " 7   SMS_4G       6246 non-null   float64\n",
      " 8   Service_Req  6276 non-null   float64\n",
      " 9   HO           6264 non-null   float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(distributionsDF.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          LocationId  MinuteWithinWeek          Voice         SMS_3G  \\\n",
      "count  272160.000000     272160.000000  272160.000000  272160.000000   \n",
      "mean      504.222222       5039.500000       0.137254       0.035780   \n",
      "std         2.897429       2909.850688       1.175929       0.347789   \n",
      "min       500.000000          0.000000       0.000000       0.000000   \n",
      "25%       502.000000       2519.750000       0.000000       0.000000   \n",
      "50%       504.000000       5039.500000       0.000000       0.000000   \n",
      "75%       506.000000       7559.250000       0.000000       0.000000   \n",
      "max       509.000000      10079.000000      24.000000      24.000000   \n",
      "\n",
      "                  PS             CS           Call         SMS_4G  \\\n",
      "count  272160.000000  272160.000000  272160.000000  272160.000000   \n",
      "mean        4.869588       2.460204       0.120065       0.227623   \n",
      "std        15.731381      11.132136       0.745263       1.151725   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         1.000000       0.000000       0.000000       0.000000   \n",
      "75%         2.000000       1.000000       0.000000       0.000000   \n",
      "max       193.000000     196.000000      12.000000      21.000000   \n",
      "\n",
      "         Service_Req             HO     WeeksGroup  \n",
      "count  272160.000000  272160.000000  272160.000000  \n",
      "mean       22.682764       2.872939       1.000000  \n",
      "std        70.437974       8.319727       0.816498  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         0.000000       0.000000       0.000000  \n",
      "50%         0.000000       0.000000       1.000000  \n",
      "75%        11.000000       0.000000       2.000000  \n",
      "max       819.000000     149.000000       2.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 272160 entries, 0 to 272159\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   LocationId        272160 non-null  int32\n",
      " 1   MinuteWithinWeek  272160 non-null  int32\n",
      " 2   Voice             272160 non-null  int32\n",
      " 3   SMS_3G            272160 non-null  int32\n",
      " 4   PS                272160 non-null  int32\n",
      " 5   CS                272160 non-null  int32\n",
      " 6   Call              272160 non-null  int32\n",
      " 7   SMS_4G            272160 non-null  int32\n",
      " 8   Service_Req       272160 non-null  int32\n",
      " 9   HO                272160 non-null  int32\n",
      " 10  WeeksGroup        272160 non-null  int32\n",
      "dtypes: int32(11)\n",
      "memory usage: 11.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = MediansDFSPAllMins.toPandas()\n",
    "print(df.describe())\n",
    "print(df.info(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- WeeksGroup: integer (nullable = true)\n",
      " |-- LocationId: integer (nullable = true)\n",
      " |-- MinuteWithinWeek: integer (nullable = true)\n",
      " |-- Voice: integer (nullable = true)\n",
      " |-- SMS_3G: integer (nullable = true)\n",
      " |-- PS: integer (nullable = true)\n",
      " |-- CS: integer (nullable = true)\n",
      " |-- Call: integer (nullable = true)\n",
      " |-- SMS_4G: integer (nullable = true)\n",
      " |-- Service_Req: integer (nullable = true)\n",
      " |-- HO: integer (nullable = true)\n",
      "\n",
      "+----------+----------+----------------+-----+------+---+---+----+------+-----------+---+\n",
      "|WeeksGroup|LocationId|MinuteWithinWeek|Voice|SMS_3G| PS| CS|Call|SMS_4G|Service_Req| HO|\n",
      "+----------+----------+----------------+-----+------+---+---+----+------+-----------+---+\n",
      "|         0|       780|             448|    0|     0|  5|  5|   0|     0|        115|  9|\n",
      "|         0|       780|            1092|    0|     0| 11|  0|   1|     5|        226| 32|\n",
      "|         0|       780|            1601|    0|     0|  1|  0|   0|     0|         72|  0|\n",
      "|         0|       780|            1645|    0|     0|  0|  0|   0|     0|         67|  0|\n",
      "|         0|       780|            1656|    0|     0|  0|  1|   0|     0|         91|  0|\n",
      "|         0|       780|            1676|    0|     0|  0|  1|   0|     0|         72|  0|\n",
      "|         0|       780|            1696|    0|     0|  1|  0|   0|     0|         71|  0|\n",
      "|         0|       780|            1790|    0|     0|  1|  0|   0|     0|         64|  2|\n",
      "|         0|       780|            2420|    1|     0| 17|  0|   2|     4|        294| 22|\n",
      "|         0|       780|            2612|    1|     0| 15|  0|   6|     2|        324| 62|\n",
      "+----------+----------+----------------+-----+------+---+---+----+------+-----------+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 483840 entries, 0 to 483839\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype\n",
      "---  ------            --------------   -----\n",
      " 0   WeeksGroup        483840 non-null  int32\n",
      " 1   LocationId        483840 non-null  int32\n",
      " 2   MinuteWithinWeek  483840 non-null  int32\n",
      " 3   Voice             483840 non-null  int32\n",
      " 4   SMS_3G            483840 non-null  int32\n",
      " 5   PS                483840 non-null  int32\n",
      " 6   CS                483840 non-null  int32\n",
      " 7   Call              483840 non-null  int32\n",
      " 8   SMS_4G            483840 non-null  int32\n",
      " 9   Service_Req       483840 non-null  int32\n",
      " 10  HO                483840 non-null  int32\n",
      "dtypes: int32(11)\n",
      "memory usage: 20.3 MB\n",
      "None\n",
      "          WeeksGroup     LocationId  MinuteWithinWeek          Voice  \\\n",
      "count  483840.000000  483840.000000     483840.000000  483840.000000   \n",
      "mean        1.000000     789.562500       5039.500000       0.328886   \n",
      "std         0.816497       5.419516       2909.848349       1.047932   \n",
      "min         0.000000     780.000000          0.000000       0.000000   \n",
      "25%         0.000000     785.750000       2519.750000       0.000000   \n",
      "50%         1.000000     789.500000       5039.500000       0.000000   \n",
      "75%         2.000000     793.500000       7559.250000       0.000000   \n",
      "max         2.000000     799.000000      10079.000000      14.000000   \n",
      "\n",
      "              SMS_3G             PS             CS           Call  \\\n",
      "count  483840.000000  483840.000000  483840.000000  483840.000000   \n",
      "mean        0.059747       4.853257       3.157135       0.828117   \n",
      "std         0.331147       7.324908       6.572653       2.059958   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       7.000000       2.000000       0.000000   \n",
      "max        21.000000      76.000000      66.000000      22.000000   \n",
      "\n",
      "              SMS_4G    Service_Req             HO  \n",
      "count  483840.000000  483840.000000  483840.000000  \n",
      "mean        2.112847     138.776976      18.123838  \n",
      "std         4.539027     207.369608      34.856057  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         0.000000       0.000000       0.000000  \n",
      "50%         0.000000      30.000000       1.000000  \n",
      "75%         2.000000     214.000000      20.000000  \n",
      "max        50.000000    1493.000000     326.000000  \n",
      "        WeeksGroup  LocationId  MinuteWithinWeek  Voice  SMS_3G  PS  CS  Call  \\\n",
      "0                0         780               448      0       0   5   5     0   \n",
      "1                0         780              1092      0       0  11   0     1   \n",
      "2                0         780              1601      0       0   1   0     0   \n",
      "3                0         780              1645      0       0   0   0     0   \n",
      "4                0         780              1656      0       0   0   1     0   \n",
      "...            ...         ...               ...    ...     ...  ..  ..   ...   \n",
      "483835           2         799              9541      0       0   4   4     0   \n",
      "483836           2         799              9694      0       0   7   4     0   \n",
      "483837           2         799              9726      1       0   7   6     0   \n",
      "483838           2         799              9757      0       0   4   1     0   \n",
      "483839           2         799             10032      0       0   0   0     0   \n",
      "\n",
      "        SMS_4G  Service_Req  HO  \n",
      "0            0          115   9  \n",
      "1            5          226  32  \n",
      "2            0           72   0  \n",
      "3            0           67   0  \n",
      "4            0           91   0  \n",
      "...        ...          ...  ..  \n",
      "483835       3          167  71  \n",
      "483836       1           97  55  \n",
      "483837       1          194  33  \n",
      "483838       4          244  39  \n",
      "483839       0           41   7  \n",
      "\n",
      "[483840 rows x 11 columns]\n",
      "computing Done in 53.76792621612549 seconds\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MinuteWithinWeek  Voice  SMS_3G    PS    CS  Call  SMS_4G  Service_Req  \\\n",
      "0                  1029    4.0     0.0  24.0  19.0     4       6          637   \n",
      "1                  1030    3.0     1.0  20.0  26.0     8       8          645   \n",
      "2                  1031    3.0     1.0  19.0  21.0     6      13          629   \n",
      "3                  1032    3.0     0.0  29.0  25.0     4       6          697   \n",
      "4                  1033    4.0     0.0  25.0  26.0     4      16          709   \n",
      "...                 ...    ...     ...   ...   ...   ...     ...          ...   \n",
      "10075              9123    0.0     0.0   1.0   1.0     0       0          120   \n",
      "10076              9124    0.0     0.0   1.0   3.0     0       0          141   \n",
      "10077              9125    0.0     0.0   0.0   1.0     0       0          115   \n",
      "10078              9126    0.0     0.0   3.0   4.0     0       0          126   \n",
      "10079              9127    0.0     0.0   2.0   3.0     0       0           99   \n",
      "\n",
      "        HO  WeeksGroup  LocationId  \n",
      "0      150           0         789  \n",
      "1      154           0         789  \n",
      "2      149           0         789  \n",
      "3      183           0         789  \n",
      "4      138           0         789  \n",
      "...    ...         ...         ...  \n",
      "10075   11           0         789  \n",
      "10076   13           0         789  \n",
      "10077   16           0         789  \n",
      "10078   20           0         789  \n",
      "10079   13           0         789  \n",
      "\n",
      "[10080 rows x 11 columns]\n",
      "      MinuteWithinWeek  Voice  SMS_3G   PS   CS  Call  SMS_4G  Service_Req  \\\n",
      "7284                 0    0.0     0.0  4.0  8.0     0       1          221   \n",
      "7285                 1    0.0     0.0  5.0  9.0     0       2          208   \n",
      "7286                 2    0.0     0.0  6.0  7.0     0       2          212   \n",
      "7287                 3    0.0     0.0  3.0  5.0     0       1          214   \n",
      "7288                 4    0.0     0.0  3.0  4.0     0       0          173   \n",
      "...                ...    ...     ...  ...  ...   ...     ...          ...   \n",
      "6717             10075    0.0     0.0  5.0  4.0     0       1          193   \n",
      "6718             10076    0.0     0.0  6.0  6.0     0       2          167   \n",
      "6719             10077    0.0     0.0  3.0  3.0     0       0          194   \n",
      "6720             10078    0.0     0.0  4.0  6.0     0       0          212   \n",
      "6721             10079    0.0     0.0  5.0  5.0     0       0          200   \n",
      "\n",
      "      HO  WeeksGroup  LocationId  \n",
      "7284  52           0         789  \n",
      "7285  50           0         789  \n",
      "7286  41           0         789  \n",
      "7287  42           0         789  \n",
      "7288  35           0         789  \n",
      "...   ..         ...         ...  \n",
      "6717  46           0         789  \n",
      "6718  34           0         789  \n",
      "6719  28           0         789  \n",
      "6720  21           0         789  \n",
      "6721  39           0         789  \n",
      "\n",
      "[10080 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "MediansDF = MediansDF.sort_values(by=['MinuteWithinWeek'])\n",
    "print(MediansDF)\n",
    "\n",
    "from anr_discret import offlineMLbyPL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T09:06:03.223334Z",
     "iopub.status.busy": "2021-07-12T09:06:03.223106Z",
     "iopub.status.idle": "2021-07-12T09:06:03.811478Z",
     "shell.execute_reply": "2021-07-12T09:06:03.810947Z",
     "shell.execute_reply.started": "2021-07-12T09:06:03.223309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregate by location & date\n",
    "metrics_3g = ['Voice','SMS_3G','PS','CS']\n",
    "metrics_4g = ['Call','SMS_4G','Service_Req','HO']\n",
    "\n",
    "cells_3g = cells_3g.groupBy(['LocInfo','Ts']).sum().drop('sum(Ts)')\n",
    "cells_4g = cells_4g.groupBy(['LocInfo','Ts']).sum().drop('sum(Ts)')\n",
    "\n",
    "for m in metrics_3g:\n",
    "    cells_3g = cells_3g.withColumnRenamed('sum('+m+')', m)\n",
    "for m in metrics_4g:\n",
    "    cells_4g = cells_4g.withColumnRenamed('sum('+m+')', m)\n",
    "    \n",
    "# Add geographic coordinates\n",
    "TOPO_FILEPATH = '/input_data/TestAngelo/DIOD/CELLS_TOPO/LocInfo_cancan_allcells_names_wgs.csv'\n",
    "topo = spark.read.csv(TOPO_FILEPATH, inferSchema=True, sep=\";\", header=True)\n",
    "\n",
    "c3 = cells_3g.alias('c3')\n",
    "c4 = cells_4g.alias('c4')\n",
    "topo = topo.alias('topo')\n",
    "c3_topo = c3.join(topo, c3.LocInfo == topo.LocInfo)\n",
    "c4_topo = c4.join(topo, c4.LocInfo == topo.LocInfo)\n",
    "\n",
    "c3_topo = c3_topo.drop(topo.LocInfo) \\\n",
    "    .drop('TECHNO') \\\n",
    "    .drop('LAC') \\\n",
    "    .drop('min_dt') \\\n",
    "    .drop('max_dt') \n",
    "c4_topo = c4_topo.drop(topo.LocInfo) \\\n",
    "    .drop('TECHNO') \\\n",
    "    .drop('LAC') \\\n",
    "    .drop('min_dt') \\\n",
    "    .drop('max_dt') \n",
    "\n",
    "# Reformat date\n",
    "c3_topo = c3_topo.na.fill(0) \\\n",
    "    .withColumn('Ts', f.col('Ts')+3600*2) \\\n",
    "    .withColumn('Ts', f.col('Ts').cast('string')) \\\n",
    "    .withColumn('Date', f.from_unixtime(f.col('Ts'), 'yyyy-MM-dd HH:mm')) \\\n",
    "    .orderBy('Date') \\\n",
    "    .drop('Ts')\n",
    "c4_topo = c4_topo.na.fill(0) \\\n",
    "    .withColumn('Ts', f.col('Ts')*60+3600*2) \\\n",
    "    .withColumn('Ts', f.col('Ts').cast('string')) \\\n",
    "    .withColumn('Date', f.from_unixtime(f.col('Ts'), 'yyyy-MM-dd HH:mm')) \\\n",
    "    .orderBy('Date') \\\n",
    "    .drop('Ts')\n",
    "\n",
    "# Agregate antennas by coordinates\n",
    "clusters3 = c3_topo.groupBy(meta).sum()\n",
    "clusters4 = c4_topo.groupBy(meta).sum()\n",
    "for m in metrics_3g:\n",
    "    clusters3 = clusters3.withColumnRenamed('sum('+m+')', m) \\\n",
    "        .drop('CI') \\\n",
    "        .drop('NOM_SITE')\n",
    "for m in metrics_4g:\n",
    "    clusters4 = clusters4.withColumnRenamed('sum('+m+')', m) \\\n",
    "        .drop('CI') \\\n",
    "        .drop('NOM_SITE')\n",
    "    \n",
    "# Reshape\n",
    "clusters3 = clusters3.drop('sum(COORD_X)') \\\n",
    "    .drop('sum(COORD_Y)') \\\n",
    "    .drop('sum(LON)') \\\n",
    "    .drop('sum(LAT)') \\\n",
    "    .drop('sum(CI)') \\\n",
    "    .orderBy('Date')\n",
    "clusters4 = clusters4.drop('sum(COORD_X)') \\\n",
    "    .drop('sum(COORD_Y)') \\\n",
    "    .drop('sum(LON)') \\\n",
    "    .drop('sum(LAT)') \\\n",
    "    .drop('sum(CI)') \\\n",
    "    .orderBy('Date')\n",
    "\n",
    "# Merge 3G and 4G data\n",
    "c3 = clusters3.alias('c3')\n",
    "c4 = clusters4.alias('c4')\n",
    "clusters = c3.join(c4, on=meta, how='outer').orderBy('Date')\n",
    "\n",
    "clusters.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Separate training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8fa5fbf1055b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yyyy-MM-dd HH:mm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# found how to navigate between weeks here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/304256/whats-the-best-way-to-find-the-inverse-of-datetime-isocalendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clusters' is not defined"
     ]
    }
   ],
   "source": [
    "clusters = clusters.withColumn('Date', f.to_timestamp(f.col('Date'), 'yyyy-MM-dd HH:mm'))\n",
    "\n",
    "# found how to navigate between weeks here\n",
    "# https://stackoverflow.com/questions/304256/whats-the-best-way-to-find-the-inverse-of-datetime-isocalendar\n",
    "\n",
    "def iso_year_start(iso_year):\n",
    "    #\"The gregorian calendar date of the first day of the given ISO year\"\n",
    "    fourth_jan = datetime.date(iso_year, 1, 4)\n",
    "    delta = datetime.timedelta(fourth_jan.isoweekday()-1)\n",
    "    return fourth_jan - delta \n",
    "\n",
    "def iso_to_gregorian(iso_year, iso_week, iso_day):\n",
    "    #\"Gregorian calendar date for the given ISO year, week and day\"\n",
    "    year_start = iso_year_start(iso_year)\n",
    "    return year_start + datetime.timedelta(days=iso_day-1, weeks=iso_week-1)\n",
    "\n",
    "\n",
    "# separating weeks within the dataset to make the training and testing tasks easier\n",
    "for wId in range(24,26):\n",
    "    TestIn = iso_to_gregorian(2019,wId,1)\n",
    "    TestOut = iso_to_gregorian(2019,wId+1,1)\n",
    "    \n",
    "    print(\"storing dates between \" + str(TestIn) + \" and \" + str(TestOut) + \" as week \" + str(wId))\n",
    "    #print(TestOut)\n",
    "    \n",
    "    #continue\n",
    "\n",
    "    #training = clusters.filter((clusters.Date < TestIn) | (clusters.Date >= TestOut)) \n",
    "    testing = clusters.filter((clusters.Date >= TestIn) & (clusters.Date < TestOut))\n",
    "    \n",
    "    print(\"found \" + str(testing.count()) + \" elements\")\n",
    "    testing.write.mode(\"overwrite\").format('parquet').save('exports/' + LocationPrefix + '/dataset_' + LocationPrefix + '_week' + str(wId) + '.parquet')\n",
    "    \n",
    "    #testing.toPandas().to_csv('exports/Paris/testing_dataset_Paris_week' + str(wId) + '.csv', index=False)\n",
    "    #training.toPandas().to_csv('exports/Paris/training_dataset_Paris_week' + str(wId) + '.csv', index=False)\n",
    "    \n",
    "    \n",
    "#TestIn = datetime(2019,4,1,0,0)\n",
    "#TestOut = datetime(2019,4,8,0,0)\n",
    "\n",
    "#sep1 = datetime(2019,4,1,0,0)\n",
    "#sep2 = datetime(2019,5,1,0,0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17591636 elements for the training part\n",
      "found 1508832 elements for the testing part\n",
      "ratio testing/training : 0.08576985108150259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:26<00:00,  6.75it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.11it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:11<00:00,  9.84s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.86it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [00:03<00:00, 56.57it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [00:06<00:00, 28.10it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [00:01<00:00, 130.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.505657e+06  1.505657e+06  1.505657e+06  1.505657e+06  1.505657e+06   \n",
      "mean   6.009633e+05  4.885617e+01  2.428648e+06  2.349625e+00 -1.580131e+01   \n",
      "std    7.002287e+02  9.433704e-03  1.049652e+03  9.536984e-03  1.679684e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.566606e+02   \n",
      "25%    6.004040e+05  4.884927e+01  2.427880e+06  2.342009e+00 -2.113810e+01   \n",
      "50%    6.009080e+05  4.885714e+01  2.428756e+06  2.348874e+00 -1.112667e+01   \n",
      "75%    6.014710e+05  4.886338e+01  2.429451e+06  2.356543e+00 -4.498597e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.490707e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.505657e+06  \n",
      "mean    1.137284e-01  \n",
      "std     3.870386e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17610582 elements for the training part\n",
      "found 1489886 elements for the testing part\n",
      "ratio testing/training : 0.08460174683607845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:26<00:00,  6.65it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:35<00:00,  5.06it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [28:59<00:00,  9.77s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.84it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:03<00:00, 56.92it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:06<00:00, 28.81it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:01<00:00, 130.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.487133e+06  1.487133e+06  1.487133e+06  1.487133e+06  1.487133e+06   \n",
      "mean   6.009675e+05  4.885622e+01  2.428653e+06  2.349683e+00 -1.557253e+01   \n",
      "std    6.999319e+02  9.396839e-03  1.045551e+03  9.532959e-03  1.717277e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.906399e+02   \n",
      "25%    6.004190e+05  4.884927e+01  2.427880e+06  2.342213e+00 -2.050502e+01   \n",
      "50%    6.009200e+05  4.885721e+01  2.428764e+06  2.349038e+00 -1.024093e+01   \n",
      "75%    6.014820e+05  4.886338e+01  2.429451e+06  2.356695e+00 -4.071460e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.466140e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.487133e+06  \n",
      "mean    1.284942e-01  \n",
      "std     4.071225e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17565234 elements for the training part\n",
      "found 1535234 elements for the testing part\n",
      "ratio testing/training : 0.08740185300121821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  6.92it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:35<00:00,  5.08it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:05<00:00,  9.81s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.83it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:03<00:00, 56.16it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:06<00:00, 27.65it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:01<00:00, 129.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.532747e+06  1.532747e+06  1.532747e+06  1.532747e+06  1.532747e+06   \n",
      "mean   6.009736e+05  4.885629e+01  2.428662e+06  2.349766e+00 -1.471656e+01   \n",
      "std    7.005660e+02  9.418594e-03  1.047972e+03  9.541613e-03  1.618057e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.583276e+02   \n",
      "25%    6.004190e+05  4.884927e+01  2.427880e+06  2.342213e+00 -1.980937e+01   \n",
      "50%    6.009410e+05  4.885724e+01  2.428767e+06  2.349319e+00 -1.008709e+01   \n",
      "75%    6.014820e+05  4.886372e+01  2.429488e+06  2.356695e+00 -3.938191e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.495355e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.532747e+06  \n",
      "mean    1.045352e-01  \n",
      "std     3.751881e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17568098 elements for the training part\n",
      "found 1532370 elements for the testing part\n",
      "ratio testing/training : 0.08722458173901353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  7.04it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:35<00:00,  5.08it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:01<00:00,  9.78s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.84it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:03<00:00, 57.12it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:06<00:00, 28.30it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:01<00:00, 133.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.529137e+06  1.529137e+06  1.529137e+06  1.529137e+06  1.529137e+06   \n",
      "mean   6.009753e+05  4.885633e+01  2.428666e+06  2.349790e+00 -1.515151e+01   \n",
      "std    7.009699e+02  9.437361e-03  1.050060e+03  9.547133e-03  1.687367e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -3.017017e+02   \n",
      "25%    6.004190e+05  4.884933e+01  2.427887e+06  2.342213e+00 -2.028553e+01   \n",
      "50%    6.009410e+05  4.885725e+01  2.428768e+06  2.349319e+00 -1.020623e+01   \n",
      "75%    6.015130e+05  4.886372e+01  2.429488e+06  2.357104e+00 -4.010241e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.706767e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.529137e+06  \n",
      "mean    1.148295e-01  \n",
      "std     3.938407e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17668026 elements for the training part\n",
      "found 1432442 elements for the testing part\n",
      "ratio testing/training : 0.08107538442608132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:26<00:00,  6.82it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:35<00:00,  5.05it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:06<00:00,  9.81s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.83it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:02<00:00, 59.38it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 28.41it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 135.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.429963e+06  1.429963e+06  1.429963e+06  1.429963e+06  1.429963e+06   \n",
      "mean   6.009784e+05  4.885629e+01  2.428662e+06  2.349832e+00 -1.357609e+01   \n",
      "std    6.992677e+02  9.493410e-03  1.056296e+03  9.523928e-03  1.318850e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.133561e+02   \n",
      "25%    6.004450e+05  4.884927e+01  2.427880e+06  2.342568e+00 -1.856353e+01   \n",
      "50%    6.009410e+05  4.885725e+01  2.428768e+06  2.349319e+00 -1.003238e+01   \n",
      "75%    6.015130e+05  4.886372e+01  2.429488e+06  2.357104e+00 -4.204532e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.652829e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.429963e+06  \n",
      "mean    6.082885e-02  \n",
      "std     2.593139e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17604262 elements for the training part\n",
      "found 1496206 elements for the testing part\n",
      "ratio testing/training : 0.08499112317233179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  7.06it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.13it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [28:55<00:00,  9.75s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.86it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:03<00:00, 58.21it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 28.39it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 135.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.494096e+06  1.494096e+06  1.494096e+06  1.494096e+06  1.494096e+06   \n",
      "mean   6.009758e+05  4.885632e+01  2.428665e+06  2.349796e+00 -1.350988e+01   \n",
      "std    6.994664e+02  9.451798e-03  1.051666e+03  9.526644e-03  1.400256e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.826566e+02   \n",
      "25%    6.004450e+05  4.884927e+01  2.427880e+06  2.342568e+00 -1.799608e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.588841e+00   \n",
      "75%    6.015130e+05  4.886396e+01  2.429515e+06  2.357104e+00 -4.021389e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.968911e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.494096e+06  \n",
      "mean    6.861808e-02  \n",
      "std     2.801435e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17779572 elements for the training part\n",
      "found 1320896 elements for the testing part\n",
      "ratio testing/training : 0.07429290198886677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  6.95it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.18it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:19<00:00,  9.88s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:03<00:00,  2.82it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:02<00:00, 60.72it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:05<00:00, 30.95it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 138.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.319008e+06  1.319008e+06  1.319008e+06  1.319008e+06  1.319008e+06   \n",
      "mean   6.009711e+05  4.885636e+01  2.428669e+06  2.349733e+00 -1.409193e+01   \n",
      "std    6.995270e+02  9.428595e-03  1.049085e+03  9.527482e-03  1.460486e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.416931e+02   \n",
      "25%    6.004190e+05  4.885029e+01  2.427994e+06  2.342213e+00 -1.886256e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.921472e+00   \n",
      "75%    6.014820e+05  4.886396e+01  2.429515e+06  2.356695e+00 -4.084582e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -9.880588e-03   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.319008e+06  \n",
      "mean    8.531942e-02  \n",
      "std     3.198473e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17544179 elements for the training part\n",
      "found 1556289 elements for the testing part\n",
      "ratio testing/training : 0.08870685826905893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:26<00:00,  6.60it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:33<00:00,  5.30it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [28:53<00:00,  9.74s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.85it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:03<00:00, 55.55it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 27.95it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 133.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.553428e+06  1.553428e+06  1.553428e+06  1.553428e+06  1.553428e+06   \n",
      "mean   6.009707e+05  4.885638e+01  2.428671e+06  2.349727e+00 -1.420566e+01   \n",
      "std    7.005708e+02  9.408659e-03  1.046866e+03  9.541695e-03  1.539550e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -3.462038e+02   \n",
      "25%    6.004190e+05  4.885029e+01  2.427994e+06  2.342213e+00 -1.900966e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.829711e+00   \n",
      "75%    6.015130e+05  4.886396e+01  2.429515e+06  2.357104e+00 -3.968806e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -1.893574e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.553428e+06  \n",
      "mean    9.047346e-02  \n",
      "std     3.401442e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 18318480 elements for the training part\n",
      "found 781988 elements for the testing part\n",
      "ratio testing/training : 0.042688476336464595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:27<00:00,  6.38it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:35<00:00,  4.94it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [30:20<00:00, 10.23s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:05<00:00,  2.72it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:02<00:00, 77.11it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:04<00:00, 41.27it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 146.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             COORD_X            LAT       COORD_Y            LON  \\\n",
      "count  781032.000000  781032.000000  7.810320e+05  781032.000000   \n",
      "mean   600972.978281      48.856230  2.428655e+06       2.349758   \n",
      "std       699.499912       0.009523  1.059538e+03       0.009527   \n",
      "min    599580.000000      48.834285  2.426213e+06       2.330786   \n",
      "25%    600445.000000      48.848800  2.427828e+06       2.342568   \n",
      "50%    600920.000000      48.857248  2.428768e+06       2.349038   \n",
      "75%    601482.000000      48.863719  2.429488e+06       2.356695   \n",
      "max    602467.000000      48.872329  2.430446e+06       2.370104   \n",
      "\n",
      "                 ALR  Anomaly_Level  \n",
      "count  781032.000000  781032.000000  \n",
      "mean      -13.745576       0.099602  \n",
      "std        14.831575       0.343146  \n",
      "min      -268.608687       0.000000  \n",
      "25%       -17.989177       0.000000  \n",
      "50%        -9.196963       0.000000  \n",
      "75%        -3.775725       0.000000  \n",
      "max        -0.023187       3.000000  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17567347 elements for the training part\n",
      "found 1533121 elements for the testing part\n",
      "ratio testing/training : 0.08727106033711295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:26<00:00,  6.82it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.13it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:18<00:00,  9.88s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:03<00:00,  2.82it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:03<00:00, 55.90it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 27.48it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 127.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.530711e+06  1.530711e+06  1.530711e+06  1.530711e+06  1.530711e+06   \n",
      "mean   6.009736e+05  4.885636e+01  2.428669e+06  2.349766e+00 -1.411424e+01   \n",
      "std    6.992587e+02  9.419778e-03  1.048103e+03  9.523821e-03  1.495839e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.207382e+02   \n",
      "25%    6.004190e+05  4.885029e+01  2.427994e+06  2.342213e+00 -1.907243e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.799137e+00   \n",
      "75%    6.014820e+05  4.886396e+01  2.429515e+06  2.356695e+00 -4.011522e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -6.868533e-03   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.530711e+06  \n",
      "mean    9.309791e-02  \n",
      "std     3.399778e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17553133 elements for the training part\n",
      "found 1547335 elements for the testing part\n",
      "ratio testing/training : 0.0881514997920884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  7.11it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.12it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:03<00:00,  9.79s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.86it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:03<00:00, 56.01it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 27.62it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:01<00:00, 130.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.544571e+06  1.544571e+06  1.544571e+06  1.544571e+06  1.544571e+06   \n",
      "mean   6.009688e+05  4.885636e+01  2.428669e+06  2.349701e+00 -1.411094e+01   \n",
      "std    7.012869e+02  9.435005e-03  1.049798e+03  9.551451e-03  1.464000e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -2.185480e+02   \n",
      "25%    6.004190e+05  4.884933e+01  2.427887e+06  2.342213e+00 -1.922052e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.920849e+00   \n",
      "75%    6.015130e+05  4.886396e+01  2.429515e+06  2.357104e+00 -4.015574e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -8.201063e-03   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.544571e+06  \n",
      "mean    9.361952e-02  \n",
      "std     3.738755e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 17654978 elements for the training part\n",
      "found 1445490 elements for the testing part\n",
      "ratio testing/training : 0.08187435860865984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:25<00:00,  6.97it/s]\n",
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.16it/s]\n",
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [29:08<00:00,  9.82s/it]\n",
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [01:02<00:00,  2.83it/s]\n",
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:02<00:00, 59.20it/s]\n",
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:06<00:00, 29.26it/s]\n",
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177/177 [00:01<00:00, 135.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            COORD_X           LAT       COORD_Y           LON           ALR  \\\n",
      "count  1.442931e+06  1.442931e+06  1.442931e+06  1.442931e+06  1.442931e+06   \n",
      "mean   6.009646e+05  4.885635e+01  2.428669e+06  2.349643e+00 -1.419713e+01   \n",
      "std    6.992094e+02  9.464687e-03  1.053101e+03  9.523160e-03  1.518542e+01   \n",
      "min    5.995800e+05  4.883429e+01  2.426213e+06  2.330786e+00 -3.008162e+02   \n",
      "25%    6.004190e+05  4.884927e+01  2.427880e+06  2.342213e+00 -1.924708e+01   \n",
      "50%    6.009200e+05  4.885725e+01  2.428768e+06  2.349038e+00 -9.820761e+00   \n",
      "75%    6.014820e+05  4.886396e+01  2.429515e+06  2.356695e+00 -3.961217e+00   \n",
      "max    6.024670e+05  4.887233e+01  2.430446e+06  2.370104e+00 -2.184786e-02   \n",
      "\n",
      "       Anomaly_Level  \n",
      "count   1.442931e+06  \n",
      "mean    9.416874e-02  \n",
      "std     3.477299e-01  \n",
      "min     0.000000e+00  \n",
      "25%     0.000000e+00  \n",
      "50%     0.000000e+00  \n",
      "75%     0.000000e+00  \n",
      "max     3.000000e+00  \n",
      "root\n",
      " |-- COORD_X: integer (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- COORD_Y: integer (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Voice: double (nullable = true)\n",
      " |-- PS: double (nullable = true)\n",
      " |-- SMS_3G: double (nullable = true)\n",
      " |-- CS: double (nullable = true)\n",
      " |-- Service_Req: double (nullable = true)\n",
      " |-- Call: double (nullable = true)\n",
      " |-- SMS_4G: double (nullable = true)\n",
      " |-- HO: double (nullable = true)\n",
      "\n",
      "found 19100468 elements for the training part\n",
      "found 0 elements for the testing part\n",
      "ratio testing/training : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:28<00:00,  6.26it/s]\n",
      "AE computing:  38%|‚ñà‚ñà‚ñà‚ñä      | 68/178 [00:14<00:24,  4.43it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now trying to load previously written data\n",
    "firstWeek = 10\n",
    "lastWeek = 25\n",
    "\n",
    "LocationPrefix = \"Paris\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "#sys.path.append('../notebooks_evelyne/')\n",
    "\n",
    "from anr_discret import offlineML\n",
    "from anr_discret import onlineML\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meta = ['COORD_X','LAT','COORD_Y','LON','Date']\n",
    "coords = ['COORD_X','LAT','COORD_Y','LON']\n",
    "metrics = ['Voice','SMS_3G','PS','CS','Call','SMS_4G','Service_Req','HO']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for testWeek in range(firstWeek+3, lastWeek+1):\n",
    "\n",
    "\n",
    "    # loading the testData\n",
    "    testData = spark.read.parquet('exports/' + LocationPrefix + '/dataset_' + LocationPrefix + '_week' + str(testWeek) + '.parquet')\n",
    "\n",
    "    # now \"unioning\" all the training data together\n",
    "    trainData = spark.read.parquet('exports/' + LocationPrefix + '/dataset_' + LocationPrefix + '_week' + str(firstWeek) + '.parquet')\n",
    "    for indWeek in range(firstWeek, lastWeek):\n",
    "        if indWeek == testWeek:\n",
    "            continue\n",
    "        trainData = trainData.union(spark.read.parquet('exports/' + LocationPrefix + '/dataset_' + LocationPrefix + '_week' + str(indWeek) + '.parquet'))\n",
    "\n",
    "    trainData.printSchema()\n",
    "    print(\"found \" + str(trainData.count()) + \" elements for the training part\")\n",
    "    print(\"found \" + str(testData.count()) + \" elements for the testing part\")\n",
    "    print(\"ratio testing/training : \" + str(testData.count()/trainData.count()))\n",
    "    \n",
    "    \n",
    "    train_df = trainData.toPandas()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # offline training part\n",
    "    \n",
    "    # extract reference signatures\n",
    "    \n",
    "    locinfos = list(set(list(zip(train_df['COORD_X'], train_df['COORD_Y']))))\n",
    "    signatures = {}\n",
    "    with tqdm(total=len(locinfos), desc='Signature extraction') as pbar:\n",
    "        for x,y in locinfos:\n",
    "            if 0 not in (x,y):\n",
    "                df = train_df.loc[(train_df['COORD_X'] == x) & (train_df['COORD_Y'] == y)]\n",
    "                sig = offlineML.signature_weekly(df, date_col='Date')\n",
    "                signatures[str(x)+str(y)] = offlineML.signature_filtered(sig, cutoff=8, metrics=metrics)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    SIGPATH = 'exports/' + LocationPrefix + '/w' + str(testWeek) + '/test_signatures_w' + str(testWeek) + '.csv'\n",
    "\n",
    "    sig_df = pd.concat([df for df in signatures.values()])\n",
    "    sig_df.to_csv(SIGPATH, index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    # train error model\n",
    "    train_df = train_df.fillna(0)\n",
    "    train_df['new_index'] = train_df.Date.map(lambda t: str(t.dayofweek)+' '+str(t.hour)+' '+str(t.minute))\n",
    "    \n",
    "    \n",
    "    real_time_signals = {}\n",
    "    locinfos = list(set(list(zip(train_df['COORD_X'], train_df['COORD_Y']))))\n",
    "    for x,y in locinfos:\n",
    "        if 0 not in (x,y):\n",
    "            real_time_signals[str(x)+str(y)] = train_df.loc[(train_df['COORD_X'] == x) & (train_df['COORD_Y'] == y)]\n",
    "    \n",
    "    \n",
    "    errors = {}\n",
    "    with tqdm(total=len(real_time_signals.keys()), desc='AE computing') as pbar:\n",
    "        for k,df in real_time_signals.items():\n",
    "            sig = signatures[k]\n",
    "            join_df = df.join(sig[metrics], on='new_index', how='inner', rsuffix='_ref')\n",
    "            errors[k] = offlineML.absolute_error(join_df, meta, metrics)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            \n",
    "    distributions = {}\n",
    "    with tqdm(total=len(errors.keys()), desc='Error distribution') as pbar:\n",
    "        for k,df in errors.items():\n",
    "            distributions[k] = offlineML.get_distrib_params(df, meta=coords, metrics=metrics)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            \n",
    "    distrib_df = pd.concat([df for df in distributions.values()])\n",
    "    distrib_df.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/test_distributions_w' + str(testWeek) + '.csv', index=False)\n",
    "    \n",
    "    # compute anomaly likelihood rates\n",
    "    with tqdm(total=len(errors.keys()), desc='ALR computing') as pbar:\n",
    "        for k,df in errors.items():\n",
    "            errors[k] = offlineML.compute_alr(df, distributions[k], metrics)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Set ALR thresholds\n",
    "    errors_df = pd.concat([df for df in errors.values()])\n",
    "\n",
    "    # apply the offlineML functions to aggregate thresholds for each antenna\n",
    "    thresholds = errors_df.groupby(coords).ALR.agg([offlineML.level1, offlineML.level2, offlineML.level3])\n",
    "\n",
    "    # don't forget to store the index or the following will be annoying\n",
    "    thresholds.reset_index(inplace=True)\n",
    "    thresholds.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/test_multilevel_thresholds_sample_test_w' + str(testWeek) + '.csv', index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Real-time detection\n",
    "    # Load real-time data and merge with signatures\n",
    "    test_df = testData.toPandas()\n",
    "    test_df.set_index('Date', inplace=True)\n",
    "    test_df.index = pd.to_datetime(test_df.index, format='%Y-%m-%d %H:%M:%S')  \n",
    "    test_df = test_df.fillna(0)\n",
    "    test_df['new_index'] = test_df.index.map(lambda t: str(t.dayofweek)+' '+str(t.hour)+' '+str(t.minute))\n",
    "\n",
    "    locinfos = list(set(list(zip(test_df['COORD_X'], test_df['COORD_Y']))))\n",
    "    real_time_signals = {}\n",
    "\n",
    "    for x,y in locinfos:\n",
    "        if 0 not in (x,y):\n",
    "            df = test_df.loc[(test_df['COORD_X'] == x) & (test_df['COORD_Y'] == y)]\n",
    "            real_time_signals[str(x)+str(y)] = df\n",
    "\n",
    "    clean = {}\n",
    "    for k,df in real_time_signals.items():\n",
    "        if len(df)>0:\n",
    "            clean[k] = df\n",
    "    real_time_signals = clean\n",
    "    \n",
    "    \n",
    "    \n",
    "    drops = []\n",
    "\n",
    "    for x,y in locinfos:\n",
    "        if 0 not in (x,y):\n",
    "            sig = sig_df.loc[(sig_df['COORD_X'] == x) & (sig_df['COORD_Y'] == y)]\n",
    "            if len(sig)>0:\n",
    "                df = real_time_signals[str(x)+str(y)]\n",
    "                real_time_signals[str(x)+str(y)] = df.join(sig[metrics], on='new_index', how='inner', rsuffix='_ref').sort_index()\n",
    "            else:\n",
    "                drops.append(str(x)+str(y))\n",
    "\n",
    "    for d in drops:\n",
    "        del real_time_signals[d]\n",
    "        \n",
    "        \n",
    "    # Apply the trained model to the data\n",
    "    # compute absolute errors\n",
    "    errors = {}\n",
    "    with tqdm(total=len(real_time_signals.keys()), desc='AE computation') as pbar:\n",
    "        for k,df in real_time_signals.items():\n",
    "            errors[k] = onlineML.absolute_error(df, meta=coords, metrics=metrics)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            \n",
    "    # Load model parameters and compute Anomaly Likelihood Rate\n",
    "    locinfos = list(set(list(zip(distrib_df['COORD_X'], distrib_df['COORD_Y']))))\n",
    "    distributions = {}\n",
    "    for x,y in locinfos:\n",
    "        if 0 not in (x,y):\n",
    "            df = distrib_df.loc[(distrib_df['COORD_X'] == x) & (distrib_df['COORD_Y'] == y)]\n",
    "            df['param'] = ['k','loc','theta']\n",
    "            df.set_index(df.param, inplace=True)\n",
    "            distributions[str(int(x))+str(int(y))] = df.drop('param', axis=1)\n",
    "\n",
    "    #thresholds = pd.read_csv('exports/Paris/multilevel_thresholds_sample_w' + str(testWeek) + '.csv')\n",
    "    thresholds['ID'] = thresholds.COORD_X.astype(str)+thresholds.COORD_Y.astype(str)\n",
    "    thresholds.set_index('ID', inplace=True)\n",
    "    thresholds = thresholds.drop(['COORD_X','COORD_Y'], axis=1)\n",
    "    \n",
    "    \n",
    "    with tqdm(total=len(errors.keys()), desc='ALR computation') as pbar:\n",
    "        for k,df in errors.items():\n",
    "            onlineML.compute_alr(df, distributions[k], metrics)    \n",
    "            pbar.update(1)\n",
    "    \n",
    "    \n",
    "    # Set anomaly levels on the real-time data\n",
    "    with tqdm(total=len(errors.keys()), desc='Setting anomaly levels') as pbar:\n",
    "        for k,df in errors.items():\n",
    "            thresh = onlineML.get_threshold(k, thresholds)\n",
    "            df = onlineML.replace_inf(df, metrics, thresh)   \n",
    "            errors[k] = onlineML.set_levels(df, thresh)\n",
    "            pbar.update(1)\n",
    "            \n",
    "    full_df = pd.concat([df[[*coords,'ALR','Anomaly_Level']] for df in errors.values()])\n",
    "    print(full_df.describe())\n",
    "    #full_df.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/test_alr_levels_w' + str(testWeek) + '.csv', index=False)\n",
    "    full_df.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/index_alr_levels_w' + str(testWeek) + '_with_index.csv')\n",
    "    \n",
    "    #break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = trainData.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M.1 Offline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "#sys.path.append('../notebooks_evelyne/')\n",
    "\n",
    "from anr_discret import offlineML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta = ['COORD_X','LAT','COORD_Y','LON','Date']\n",
    "coords = ['COORD_X','LAT','COORD_Y','LON']\n",
    "metrics = ['Voice','SMS_3G','PS','CS','Call','SMS_4G','Service_Req','HO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Extract reference signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Signature extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:34<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "locinfos = list(set(list(zip(train_df['COORD_X'], train_df['COORD_Y']))))\n",
    "signatures = {}\n",
    "with tqdm(total=len(locinfos), desc='Signature extraction') as pbar:\n",
    "    for x,y in locinfos:\n",
    "        if 0 not in (x,y):\n",
    "            df = train_df.loc[(train_df['COORD_X'] == x) & (train_df['COORD_Y'] == y)]\n",
    "            sig = offlineML.signature_weekly(df, date_col='Date')\n",
    "            signatures[str(x)+str(y)] = offlineML.signature_filtered(sig, cutoff=8, metrics=metrics)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SIGPATH = 'exports/' + LocationPrefix + '/w' + str(testWeek) + '/signatures_w' + str(testWeek) + '.csv'\n",
    "\n",
    "sig_df = pd.concat([df for df in signatures.values()])\n",
    "sig_df.to_csv(SIGPATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Train error model\n",
    "### 1.2.1 Compute absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "train_df['new_index'] = train_df.Date.map(lambda t: str(t.dayofweek)+' '+str(t.hour)+' '+str(t.minute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:46:39.597660Z",
     "iopub.status.busy": "2021-07-15T15:46:39.597299Z",
     "iopub.status.idle": "2021-07-15T15:47:02.351492Z",
     "shell.execute_reply": "2021-07-15T15:47:02.350698Z",
     "shell.execute_reply.started": "2021-07-15T15:46:39.597626Z"
    }
   },
   "outputs": [],
   "source": [
    "real_time_signals = {}\n",
    "locinfos = list(set(list(zip(train_df['COORD_X'], train_df['COORD_Y']))))\n",
    "for x,y in locinfos:\n",
    "    if 0 not in (x,y):\n",
    "        real_time_signals[str(x)+str(y)] = train_df.loc[(train_df['COORD_X'] == x) & (train_df['COORD_Y'] == y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:47:02.353270Z",
     "iopub.status.busy": "2021-07-15T15:47:02.353052Z",
     "iopub.status.idle": "2021-07-15T15:47:34.342214Z",
     "shell.execute_reply": "2021-07-15T15:47:34.341588Z",
     "shell.execute_reply.started": "2021-07-15T15:47:02.353246Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:31<00:00,  5.57it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "with tqdm(total=len(real_time_signals.keys()), desc='AE computing') as pbar:\n",
    "    for k,df in real_time_signals.items():\n",
    "        sig = signatures[k]\n",
    "        join_df = df.join(sig[metrics], on='new_index', how='inner', rsuffix='_ref')\n",
    "        errors[k] = offlineML.absolute_error(join_df, meta, metrics)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T13:29:04.534182Z",
     "iopub.status.busy": "2021-07-15T13:29:04.533892Z",
     "iopub.status.idle": "2021-07-15T13:53:13.328022Z",
     "shell.execute_reply": "2021-07-15T13:53:13.327271Z",
     "shell.execute_reply.started": "2021-07-15T13:29:04.534153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error distribution: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [24:08<00:00,  8.14s/it]\n"
     ]
    }
   ],
   "source": [
    "distributions = {}\n",
    "with tqdm(total=len(errors.keys()), desc='Error distribution') as pbar:\n",
    "    for k,df in errors.items():\n",
    "        distributions[k] = offlineML.get_distrib_params(df, meta=coords, metrics=metrics)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:52:08.360660Z",
     "iopub.status.busy": "2021-07-15T15:52:08.360389Z",
     "iopub.status.idle": "2021-07-15T15:52:08.404659Z",
     "shell.execute_reply": "2021-07-15T15:52:08.404238Z",
     "shell.execute_reply.started": "2021-07-15T15:52:08.360633Z"
    }
   },
   "outputs": [],
   "source": [
    "distrib_df = pd.concat([df for df in distributions.values()])\n",
    "distrib_df.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/distributions_w' + str(testWeek) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Compute Anomaly Likelihood Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T15:52:11.396877Z",
     "iopub.status.busy": "2021-07-15T15:52:11.396585Z",
     "iopub.status.idle": "2021-07-15T15:53:05.472627Z",
     "shell.execute_reply": "2021-07-15T15:53:05.471684Z",
     "shell.execute_reply.started": "2021-07-15T15:52:11.396842Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALR computing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:54<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(errors.keys()), desc='ALR computing') as pbar:\n",
    "    for k,df in errors.items():\n",
    "        errors[k] = offlineML.compute_alr(df, distributions[k], metrics)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Set ALR thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:16:41.463972Z",
     "iopub.status.busy": "2021-07-15T17:16:41.463672Z",
     "iopub.status.idle": "2021-07-15T17:16:52.186635Z",
     "shell.execute_reply": "2021-07-15T17:16:52.186016Z",
     "shell.execute_reply.started": "2021-07-15T17:16:41.463945Z"
    }
   },
   "outputs": [],
   "source": [
    "errors_df = pd.concat([df for df in errors.values()])\n",
    "\n",
    "# apply the offlineML functions to aggregate thresholds for each antenna\n",
    "thresholds = errors_df.groupby(coords).ALR.agg([offlineML.level1, offlineML.level2, offlineML.level3])\n",
    "\n",
    "# don't forget to store the index or the following will be annoying\n",
    "thresholds.reset_index(inplace=True)\n",
    "thresholds.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/multilevel_thresholds_sample_test_w' + str(testWeek) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M.2 Real-time detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T14:24:38.703749Z",
     "iopub.status.busy": "2021-07-15T14:24:38.703429Z",
     "iopub.status.idle": "2021-07-15T14:24:38.720507Z",
     "shell.execute_reply": "2021-07-15T14:24:38.719853Z",
     "shell.execute_reply.started": "2021-07-15T14:24:38.703703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from anr_discret import onlineML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T14:24:43.015957Z",
     "iopub.status.busy": "2021-07-15T14:24:43.015683Z",
     "iopub.status.idle": "2021-07-15T14:24:43.019360Z",
     "shell.execute_reply": "2021-07-15T14:24:43.018754Z",
     "shell.execute_reply.started": "2021-07-15T14:24:43.015932Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = ['COORD_X','LAT','COORD_Y','LON','Date']\n",
    "coords = ['COORD_X','LAT','COORD_Y','LON']\n",
    "metrics = ['Voice','SMS_3G','PS','CS','Call','SMS_4G','Service_Req','HO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load real-time data and merge with signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T14:35:55.992508Z",
     "iopub.status.busy": "2021-07-15T14:35:55.992246Z",
     "iopub.status.idle": "2021-07-15T14:36:44.701938Z",
     "shell.execute_reply": "2021-07-15T14:36:44.701231Z",
     "shell.execute_reply.started": "2021-07-15T14:35:55.992484Z"
    }
   },
   "outputs": [],
   "source": [
    "#TESTINGPATH = 'exports/Paris/testing_dataset_NotreDame.csv'\n",
    "\n",
    "#testing = pd.read_csv(TESTINGPATH, sep=',').drop('Unnamed: 0', axis=1)\n",
    "#testing.set_index('Date', inplace=True)\n",
    "#testing.index = pd.to_datetime(testing.index, format='%Y-%m-%d %H:%M:%S')  \n",
    "#testing = testing.fillna(0)\n",
    "#testing['new_index'] = testing.index.map(lambda t: str(t.dayofweek)+' '+str(t.hour)+' '+str(t.minute))\n",
    "\n",
    "# loading the testData through spark, when needed\n",
    "#testData = spark.read.parquet('exports/Paris/dataset_Paris_week' + str(testWeek) + '.parquet')\n",
    "\n",
    "test_df = testData.toPandas()\n",
    "test_df.set_index('Date', inplace=True)\n",
    "test_df.index = pd.to_datetime(test_df.index, format='%Y-%m-%d %H:%M:%S')  \n",
    "test_df = test_df.fillna(0)\n",
    "test_df['new_index'] = test_df.index.map(lambda t: str(t.dayofweek)+' '+str(t.hour)+' '+str(t.minute))\n",
    "\n",
    "locinfos = list(set(list(zip(test_df['COORD_X'], test_df['COORD_Y']))))\n",
    "real_time_signals = {}\n",
    "\n",
    "for x,y in locinfos:\n",
    "    if 0 not in (x,y):\n",
    "        df = test_df.loc[(test_df['COORD_X'] == x) & (test_df['COORD_Y'] == y)]\n",
    "        real_time_signals[str(x)+str(y)] = df\n",
    "        \n",
    "clean = {}\n",
    "for k,df in real_time_signals.items():\n",
    "    if len(df)>0:\n",
    "        clean[k] = df\n",
    "real_time_signals = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T14:56:29.367443Z",
     "iopub.status.busy": "2021-07-15T14:56:29.367223Z",
     "iopub.status.idle": "2021-07-15T14:56:31.805158Z",
     "shell.execute_reply": "2021-07-15T14:56:31.804522Z",
     "shell.execute_reply.started": "2021-07-15T14:56:29.367419Z"
    }
   },
   "outputs": [],
   "source": [
    "#SIGPATH = 'exports/Paris/signatures_NotreDame_w' + str(testWeek) + '.csv'\n",
    "\n",
    "#sig_df = pd.read_csv(SIGPATH).fillna(0)\n",
    "\n",
    "drops = []\n",
    "\n",
    "for x,y in locinfos:\n",
    "    if 0 not in (x,y):\n",
    "        sig = sig_df.loc[(sig_df['COORD_X'] == x) & (sig_df['COORD_Y'] == y)]\n",
    "        if len(sig)>0:\n",
    "            df = real_time_signals[str(x)+str(y)]\n",
    "            real_time_signals[str(x)+str(y)] = df.join(sig[metrics], on='new_index', how='inner', rsuffix='_ref').sort_index()\n",
    "        else:\n",
    "            drops.append(str(x)+str(y))\n",
    "\n",
    "for d in drops:\n",
    "    del real_time_signals[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Apply the trained model to the data\n",
    "### 2.2.1 Compute absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T14:57:00.374737Z",
     "iopub.status.busy": "2021-07-15T14:57:00.374494Z",
     "iopub.status.idle": "2021-07-15T14:57:03.041158Z",
     "shell.execute_reply": "2021-07-15T14:57:03.040565Z",
     "shell.execute_reply.started": "2021-07-15T14:57:00.374684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 176/176 [00:02<00:00, 66.24it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "with tqdm(total=len(real_time_signals.keys()), desc='AE computation') as pbar:\n",
    "    for k,df in real_time_signals.items():\n",
    "        errors[k] = onlineML.absolute_error(df, meta=coords, metrics=metrics)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Load model parameters and compute Anomaly Likelihood Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:20:28.857506Z",
     "iopub.status.busy": "2021-07-15T17:20:28.857268Z",
     "iopub.status.idle": "2021-07-15T17:20:29.206961Z",
     "shell.execute_reply": "2021-07-15T17:20:29.206436Z",
     "shell.execute_reply.started": "2021-07-15T17:20:28.857481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             COORD_X         LAT       COORD_Y         LON      level1  \\\n",
      "count     178.000000  178.000000  1.780000e+02  178.000000  178.000000   \n",
      "mean   600968.657303   48.856379  2.428671e+06    2.349699  -32.895307   \n",
      "std       713.653416    0.009313  1.036189e+03    0.009720   11.597300   \n",
      "min    599580.000000   48.834285  2.426213e+06    2.330786  -67.279578   \n",
      "25%    600407.750000   48.850317  2.427997e+06    2.342060  -40.236093   \n",
      "50%    600930.500000   48.857242  2.428768e+06    2.349178  -32.000982   \n",
      "75%    601527.250000   48.863635  2.429479e+06    2.357305  -24.125937   \n",
      "max    602467.000000   48.872329  2.430446e+06    2.370104  -12.342845   \n",
      "\n",
      "           level2      level3  \n",
      "count  178.000000  178.000000  \n",
      "mean   -58.865775  -97.737382  \n",
      "std     19.868445   30.959401  \n",
      "min   -130.594862 -181.218277  \n",
      "25%    -69.608578 -122.041490  \n",
      "50%    -55.385635  -92.636212  \n",
      "75%    -43.706491  -71.322860  \n",
      "max    -21.751426  -33.928148  \n"
     ]
    }
   ],
   "source": [
    "#distrib_params = pd.read_csv('exports/Paris/distributions_NotreDame_w' + str(testWeek) + '.csv').drop('Unnamed: 0', axis=1)\n",
    "\n",
    "locinfos = list(set(list(zip(distrib_df['COORD_X'], distrib_df['COORD_Y']))))\n",
    "distributions = {}\n",
    "for x,y in locinfos:\n",
    "    if 0 not in (x,y):\n",
    "        df = distrib_df.loc[(distrib_df['COORD_X'] == x) & (distrib_df['COORD_Y'] == y)]\n",
    "        df['param'] = ['k','loc','theta']\n",
    "        df.set_index(df.param, inplace=True)\n",
    "        distributions[str(int(x))+str(int(y))] = df.drop('param', axis=1)\n",
    "        \n",
    "#thresholds = pd.read_csv('exports/Paris/multilevel_thresholds_sample_w' + str(testWeek) + '.csv')\n",
    "thresholds['ID'] = thresholds.COORD_X.astype(str)+thresholds.COORD_Y.astype(str)\n",
    "thresholds.set_index('ID', inplace=True)\n",
    "thresholds = thresholds.drop(['COORD_X','COORD_Y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:21:11.095482Z",
     "iopub.status.busy": "2021-07-15T17:21:11.095221Z",
     "iopub.status.idle": "2021-07-15T17:21:56.726116Z",
     "shell.execute_reply": "2021-07-15T17:21:56.725196Z",
     "shell.execute_reply.started": "2021-07-15T17:21:11.095457Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALR computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:45<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(errors.keys()), desc='ALR computation') as pbar:\n",
    "    for k,df in errors.items():\n",
    "        onlineML.compute_alr(df, distributions[k], metrics)    \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Set anomaly levels on the real-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:22:45.104181Z",
     "iopub.status.busy": "2021-07-15T17:22:45.103800Z",
     "iopub.status.idle": "2021-07-15T17:22:51.993346Z",
     "shell.execute_reply": "2021-07-15T17:22:51.992702Z",
     "shell.execute_reply.started": "2021-07-15T17:22:45.104146Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting anomaly levels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178/178 [00:06<00:00, 25.87it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(errors.keys()), desc='Setting anomaly levels') as pbar:\n",
    "    for k,df in errors.items():\n",
    "        thresh = onlineML.get_threshold(k, thresholds)\n",
    "        df = onlineML.replace_inf(df, metrics, thresh)   \n",
    "        errors[k] = onlineML.set_levels(df, thresh)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:28:45.431786Z",
     "iopub.status.busy": "2021-07-15T17:28:45.431424Z",
     "iopub.status.idle": "2021-07-15T17:30:04.961494Z",
     "shell.execute_reply": "2021-07-15T17:30:04.960395Z",
     "shell.execute_reply.started": "2021-07-15T17:28:45.431751Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([df[[*coords,'ALR','Anomaly_Level']] for df in errors.values()])\n",
    "#print(full_df.describe())\n",
    "full_df.to_csv('exports/' + LocationPrefix + '/w' + str(testWeek) + '/alr_levels_w' + str(testWeek) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization by antenna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:30:04.963736Z",
     "iopub.status.busy": "2021-07-15T17:30:04.963484Z",
     "iopub.status.idle": "2021-07-15T17:30:05.896768Z",
     "shell.execute_reply": "2021-07-15T17:30:05.896224Z",
     "shell.execute_reply.started": "2021-07-15T17:30:04.963687Z"
    }
   },
   "outputs": [],
   "source": [
    "from anr_discret import carto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T14:30:00.976985Z",
     "iopub.status.busy": "2021-06-25T14:30:00.976631Z",
     "iopub.status.idle": "2021-06-25T14:30:00.981737Z",
     "shell.execute_reply": "2021-06-25T14:30:00.981110Z",
     "shell.execute_reply.started": "2021-06-25T14:30:00.976957Z"
    }
   },
   "outputs": [],
   "source": [
    "#k = '6007152428426' \n",
    "#df,err = real_time_signals[k], errors[k]\n",
    "#thresh = thresholds.loc[thresholds.index==k].iloc[0]\n",
    "#dates = [datetime(2019,4,15,18,50), datetime(2019,4,15,18,57), datetime(2019,4,15,19,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-15T17:34:09.122278Z",
     "iopub.status.busy": "2021-07-15T17:34:09.122049Z"
    }
   },
   "outputs": [],
   "source": [
    "carto.create_heatmap(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
